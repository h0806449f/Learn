{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification  \n",
    "from Note   \n",
    "1. 引入資料集  \n",
    "2. 找出資料特徵 & 關聯係數\n",
    "3. 將資料分組 (實驗組 & 對照組)  \n",
    "4. 做成決策樹 & 訓練模型\n",
    "5. 繪出決策樹\n",
    "6. 帶入對照組資料，預測\n",
    "7. 正確率 (accuracy_score)\n",
    "8. 剖析正確率 (混淆矩陣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 引入資料集\n",
    "iris = load_iris()\n",
    "\n",
    "# 做成df\n",
    "x = pd.DataFrame(iris[\"data\"], columns=iris[\"feature_names\"])\n",
    "y = pd.DataFrame(iris[\"target\"])\n",
    "\n",
    "# 轉array\n",
    "xarray = np.array(x)\n",
    "yarray = np.array(y)\n",
    "iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 分割資料\n",
    "x_train, x_test, y_train, y_test = train_test_split(xarray, yarray, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 做成決策樹\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# 導入訓練資料\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(12,12))\n",
    "# 特徵名稱, 分類類別, 圖框是否上色\n",
    "plot_tree(clf, feature_names=iris[\"feature_names\"], class_names=iris[\"target_names\"], filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 帶入答案，檢視模型合理性\n",
    "pre = clf.predict(x_test)\n",
    "\n",
    "# 做出test檔案的df + 預測值 -> 進一步檢視\n",
    "testsample = pd.DataFrame(x_test, columns=iris[\"feature_names\"])\n",
    "testans = pd.DataFrame(y_test, columns=[\"target\"])\n",
    "testpre = pd.DataFrame(pre, columns=[\"predicted_target\"])\n",
    "test_total = pd.concat([testsample, testans, testpre], axis=1)\n",
    "\n",
    "score = accuracy_score(y_test, pre)\n",
    "print(f\"精準度: {score}\")\n",
    "\n",
    "test_total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression  \n",
    "from note  \n",
    "1. 引入資料集  \n",
    "2. 將資料分組 (實驗組 & 對照組)  \n",
    "3. 做成決策樹 & 訓練模型\n",
    "4. 繪出決策樹\n",
    "5. 帶入對照組資料，預測\n",
    "6. 正確率 (R2_score)\n",
    "7. 剖析正確率 (混淆矩陣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 此為tsv檔案\n",
    "df = pd.read_csv(r\"D:\\Learn\\Machine_Learn\\_sklearn_diabetes.csv\", encoding=\"utf-8\", sep=\"\\t\")\n",
    "\n",
    "# 做成df\n",
    "x = df.drop([\"Y\"], axis=1)\n",
    "y = df[\"Y\"]\n",
    "\n",
    "# 轉array\n",
    "xarray = np.array(x)\n",
    "yarray = np.array(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 分割資料\n",
    "x_train, x_test, y_train, y_test = train_test_split(xarray, yarray, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 做成決策樹\n",
    "reg = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "# 導入訓練資料\n",
    "reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(15,15))\n",
    "plot_tree(reg, feature_names=x.columns, filled=True, fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 帶入答案，檢視模型合理性\n",
    "pre = reg.predict(x_test)\n",
    "score = r2_score(y_test, pre)\n",
    "\n",
    "# 做出test檔案的df + 預測值 -> 進一步檢視\n",
    "testsample1 = pd.DataFrame(x_test, columns=x.columns)\n",
    "testans1 = pd.DataFrame(y_test, columns=[\"target_Y\"])\n",
    "testpre1 = pd.DataFrame(pre, columns=[\"predicted_target_Y\"])\n",
    "\n",
    "test_total1 = pd.concat([testsample1, testans1, testpre1], axis=1)\n",
    "\n",
    "print(f\"預測準確度: {score}\")\n",
    "test_total1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster  \n",
    "from note  \n",
    "1. 引入資料集 & 整理資料\n",
    "2. 將資料分組 (實驗組 & 對照組)  \n",
    "3. 尋找K值 -> 畫分群圖 (K means)\n",
    "4. 可畫圖找K值\n",
    "5. 計算K值的正確率 (silhouette_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新導入iris 假設不知道分類\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# 做成df\n",
    "x = pd.DataFrame(iris[\"data\"], columns=iris[\"feature_names\"])\n",
    "y = pd.DataFrame(iris[\"target\"], columns=[\"target\"])\n",
    "df = pd.concat([x,y], axis=1)\n",
    "\n",
    "# 轉array\n",
    "xarray = np.array(x)\n",
    "yarray = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分資料\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(xarray, yarray, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 先自己假設分3群\n",
    "clu = KMeans(n_clusters=3)\n",
    "\n",
    "# 帶入訓練資料\n",
    "clu.fit(x_train)\n",
    "\n",
    "# 對train的資料貼標籤\n",
    "clu.labels_\n",
    "\n",
    "# 計算準確度分數\n",
    "silhouette_score(x_train, clu.labels_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster  \n",
    "1. 資料中並沒有答案\n",
    "2. 所以計算出最適合的KMeans時，我們可以自己對labels分出來的資料命名 clusterA, clusterB ...\n",
    "3. 所以沒有正確答案與否的問題\n",
    "4. silhouette_score 也並非正確率分數 而是各個資料相聚程度的分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for how_many_cluster in range(2,21):\n",
    "    clu = KMeans(n_clusters=how_many_cluster, n_init=\"auto\")\n",
    "    clu.fit(x_train)\n",
    "    gather_score = silhouette_score(x_train, clu.labels_)\n",
    "    print(f\"分成 {how_many_cluster} 群時，資料聚合分數為:{gather_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢測文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常用函示庫\n",
    "# opencc-python 簡繁轉換\n",
    "# rake-nltk     處理英文片語\n",
    "# TF-IDF        詞彙權重分數 (TF一份文件中出現次數 / IDF多份文件中出現次數)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡繁轉換\n",
    "from opencc import OpenCC\n",
    "to_convert = \"\"\"从前，有一只蜘蛛，在寺庙的廊庑下静静地结网。由于她经常听到讲经诵法，所以一千年过去了，她变得有些懂得佛理了。 \n",
    "有一天，佛从这间寺庙路过，看到了这只有佛缘的蜘蛛，于是问她：“你说，什么是最珍贵的？”蜘蛛想了想说：“是得不到和已失去。”佛笑笑，然后走了。 \n",
    "就这样，一千年过去了，蜘蛛一直被香火熏陶着，变得更深沉更知佛法。有一天，佛又路过这个寺庙，于是又问她：“现在你修行加深了，你认为什么是最珍贵的呢？”蜘蛛不假思索地说：“还是得不到和已失去。”佛又微笑着走了。\n",
    "\"\"\"\n",
    "\n",
    "cc = OpenCC(\"s2twp\")\n",
    "to_convert = to_convert.replace(\"\\n\",\"\")\n",
    "converted = cc.convert(to_convert)\n",
    "converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詩詞分析 - 讀取資料集\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"D:\\Learn\\Machine_Learn\\_poem_train.csv\", encoding=\"utf-8\")\n",
    "test = pd.read_csv(\"D:\\Learn\\Machine_Learn\\_poem_test.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 詩詞分析 - 統計: 作者數量, 詩數量\n",
    "train[\"作者\"].value_counts()  # -> 杜甫  1157 /  李白  969 / 白居易  605\n",
    "\n",
    "# 取index\n",
    "poets = train[\"作者\"].value_counts().index  # -> ['杜甫', '李白', '白居易']\n",
    "\n",
    "# enumerate 迭代 並給迭代的內容index\n",
    "poets_2_index = {poet:index for index, poet in enumerate(poets)}\n",
    "poets_2_index # -> {'杜甫': 0, '李白': 1, '白居易': 2}\n",
    "\n",
    "index_2_poets = {index:poet for index, poet in enumerate(poets)}\n",
    "index_2_poets # -> {0: '杜甫', 1: '李白', 2: '白居易'}\n",
    "\n",
    "# 將答案轉變為數字 (ML 無法有文字)\n",
    "y_train = train[\"作者\"].replace(poets_2_index)\n",
    "y_test = test[\"作者\"].replace(poets_2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\李重誼\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.882 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      日照 香爐生 紫煙 ， 遙看 瀑布 掛 前川 。 飛流 直下 三千尺 ， 疑是 銀河 落九天 。\n",
       "1     朝辭 白帝 彩雲間 ， 千裡 江陵 一日 還 。 兩岸 猿聲 啼 不住 ， 輕舟 已過 萬 ...\n",
       "2      李白 乘舟 將欲行 ， 忽聞 岸上 踏歌 聲 。 桃花潭水 深 千尺 ， 不及 汪倫送 我情 。\n",
       "3       故人 西辭黃鶴樓 ， 煙花 三月 下揚州 。 孤帆 遠影 碧空 儘 ， 唯見長 江天 際流 。\n",
       "4                 危樓 高 百尺 ， 手可摘 星辰 。 不敢 高聲語 ， 恐驚 天上 人 。\n",
       "5                  床前 明月光 ， 疑是 地上 霜 。 舉頭 望明月 ， 低頭思 故鄉 。\n",
       "6     天門 中斷 楚江 開 ， 碧水 東流 至此 回 。 兩岸 青山 相對 出 ， 孤帆 一片 日...\n",
       "7               眾鳥 高 飛 儘 ， 孤雲獨 去 閒 。 相看 兩不厭 ， 隻 有 敬亭山 。\n",
       "8     鳳凰 台上 鳳凰遊 ， 鳳去 台空江 自流 。 吳宮 花草 埋 幽徑 ， 晉代 衣冠 成古丘...\n",
       "9     渡遠 荊門外 ， 來 從 楚國遊 。 山 隨 平野 儘 ， 江入 大荒 流 。 月 下 飛天...\n",
       "10    百川 日東流 ， 客去 亦 不息 。 我 生苦 漂 蕩 ， 何時 有 終極 。 讚 公 釋 ...\n",
       "11    細泉 兼 輕冰 ， 沮洳 棧道 濕 。 不辭 辛苦 行 ， 迫此 短景急 。 石門 雪雲隘 ...\n",
       "12    首路 栗亭 西 ， 尚想 鳳凰村 。 季冬 攜 童稚 ， 辛苦 赴 蜀門 。 南登 木皮 嶺...\n",
       "13    落日 在 簾 鉤 ， 溪邊 春事幽 。 芳菲 緣岸 圃 ， 樵 爨 倚灘 舟 。 啅 雀 爭...\n",
       "14    竇侍 禦 ， 驥 之子 ， 鳳之雛 。 年 未 三十 忠義俱 ， 骨鯁 絕代 無 。 炯 如...\n",
       "15    百草 競春華 ， 麗春應 最勝 。 少須 好 顏色 ， 多漫枝條 剩 。 紛紛 桃李 枝 ，...\n",
       "16    何年 顧虎頭 ， 滿壁畫 瀛州 。 赤 日 石林 氣 ， 青天 江海 流 。 錫飛常 近鶴 ...\n",
       "17    野寺 隱喬木 ， 山僧 高下 居 。 石門 日色異 ， 絳 氣橫 扶疏 。 窈窕 入風 磴 ...\n",
       "18    西川 有 杜鵑 ， 東川 無 杜鵑 。 涪萬 無 杜鵑 ， 雲安有 杜鵑 。 我 昔遊錦城 ...\n",
       "19    小奴 縛雞 向 市 賣 ， 雞 被縛 急 相 喧爭 。 家中 厭雞 食蟲 蟻 ， 不知 雞賣...\n",
       "20    管妙 弦 清歌 入 雲 ， 老人 合眼 醉醺醺 。 誠知 不及 當年 聽 ， 猶覺 聞時 勝...\n",
       "21    追歡 逐樂少 閒時 ， 補帖 平生 得事遲 。 何處 花開 曾後看 ？ 誰家 酒熟 不 先知...\n",
       "22    歲 陰生計 兩 蹉跎 ， 相顧 悠悠 醉且 歌 。 廚冷 難留 烏止 屋 ， 門閒 可 與 ...\n",
       "23    雨 砌 長 寒蕪 ， 風庭 落秋果 。 窗間 有 閒叟 ， 儘 日 看 書 坐 。 書中見 ...\n",
       "24    睡足 肢體 暢 ， 晨起 開 中堂 。 初旭泛 簾幕 ， 微風 拂 衣裳 。 二婢 扶 盥櫛...\n",
       "25    履道 西門 有 弊居 ， 池塘 竹樹繞 君廬 。 豪華肥壯 雖無分 ， 飽暖安閒 即 有 餘...\n",
       "26    昨日 複 今辰 ， 悠悠 七十 春 。 所經 多 故處 ， 卻 想 似 前身 。 散 秩優遊...\n",
       "27    不 與 老為期 ， 因何 兩鬢絲 ？ 才 應免 夭促 ， 便 已 及 衰 羸 。 昨夜 夢 ...\n",
       "28    暖床 斜 臥日 曛 腰 ， 一覺 閒眠 百病 銷 。 儘 日 一 飧 茶 兩 碗 ， 更無所...\n",
       "29    選石 鋪 新路 ， 安橋 壓古堤 。 似 從 銀漢下 ， 落傍玉 川西 。 影定 欄杆 倒 ...\n",
       "Name: 內容, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jieba 分詞\n",
    "import jieba\n",
    "\n",
    "\n",
    "# 定義流程 -> apply to DF\n",
    "def jieba_cut(s):\n",
    "    return \" \".join(jieba.cut(s))\n",
    "\n",
    "# 將訓練資料分詞\n",
    "x_train = train[\"內容\"].apply(jieba_cut)\n",
    "x_test = test[\"內容\"].apply(jieba_cut)\n",
    "\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_transform vs transform\n",
    "# fit       找出分詞趨勢 創立欄位\n",
    "# transform 依照分詞趨勢 將發現的詞填入欄位\n",
    "# test的資料不用再次fit  \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "# fit_transform, 列出找到的詞彙\n",
    "x_train_vec = vec.fit_transform(x_train)\n",
    "vec.vocabulary_\n",
    "\n",
    "# transform\n",
    "x_test_vec = vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 單純貝氏 - MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# test 轉 array\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# clf, 平滑化係數 (有資料數值為0的情形)\n",
    "clf = MultinomialNB(alpha=0.2)\n",
    "clf.fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正確率\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "pre = clf.predict(x_test_vec)\n",
    "\n",
    "accuracy_score(y_test, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>杜甫</th>\n",
       "      <th>李白</th>\n",
       "      <th>白居易</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>杜甫</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>李白</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>白居易</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     杜甫  李白  白居易\n",
       "杜甫   10   0    0\n",
       "李白    1   8    1\n",
       "白居易   1   1    8"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 混淆矩陣\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "mat = confusion_matrix(y_test, pre)\n",
    "pd.DataFrame(mat, index=[f\"{p}\" for p in poets], columns=[f\"{p}\" for p in poets])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
