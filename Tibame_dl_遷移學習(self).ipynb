{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XS67M_-3Wv8bcCLD49qpabnVnvZX0pJA",
      "authorship_tag": "ABX9TyOgM3IxF99bC8MxPsAYOY3j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h0806449f/Learn/blob/main/Tibame_dl_%E9%81%B7%E7%A7%BB%E5%AD%B8%E7%BF%92(self).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75qDyFB4voQk"
      },
      "outputs": [],
      "source": [
        "!gdown \"1DE7nQ-4QN5tlasKo8-AIlZBg3p7FyKer\" --output test.zip\n",
        "!unzip test.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown \"1GLMtdlvdZVthqTQvi4dQfJKZet0T3Gvo\" --output train.zip\n",
        "!unzip train.zip"
      ],
      "metadata": {
        "id": "gqmw0cE24sZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#遷移學習"
      ],
      "metadata": {
        "id": "FhjNv9py6CyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VGG16 (https://keras.io/zh/applications/#vgg16)\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "\n",
        "vgg = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "# include_top 使否要包含VGG16的MLP ?\n",
        "# input_shape 圖片大小\n",
        "\n",
        "\n",
        "vgg.summary()"
      ],
      "metadata": {
        "id": "h489QKQw6Y7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "# 先不讀取圖片 真的要訓練時才讀取\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# 創立 DataFrame 儲存路徑與資料答案\n",
        "df_cat = pd.DataFrame(columns=[\"path\", \"target\"])\n",
        "\n",
        "for p in glob.glob(\"train/cat.*.jpg\"):\n",
        "    s = pd.Series([p, 0], index=[\"path\", \"target\"])\n",
        "    df_cat = df_cat.append(s, ignore_index=True)\n",
        "\n",
        "df_dog = pd.DataFrame(columns=[\"path\", \"target\"])\n",
        "\n",
        "for p in glob.glob(\"train/dog.*.jpg\"):\n",
        "    s = pd.Series([p, 1], index=[\"path\", \"target\"])\n",
        "    df_dog = df_dog.append(s, ignore_index=True)"
      ],
      "metadata": {
        "id": "sNWB67FD-7iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_cat, df_dog], axis=0, ignore_index=True)\n",
        "df"
      ],
      "metadata": {
        "id": "UjXG_4cMDC9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 隨機讀取圖片 檢查一下\n",
        "from tensorflow.keras.utils import load_img\n",
        "import random\n",
        "\n",
        "\n",
        "random_idx = random.randint(0, 24999)\n",
        "print(\"下方圖片路徑:\", df[\"path\"][random_idx])\n",
        "img = load_img(df[\"path\"][random_idx])\n",
        "print(\"下方圖片大小:\", img.size)\n",
        "img"
      ],
      "metadata": {
        "id": "-96vbtxyD60S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = load_img(df[\"path\"][random_idx], target_size=(224, 224))\n",
        "# target_size -> 修改原本圖片大小 -> 以符合 VGG16 的 input_size\n",
        "\n",
        "print(\"下方圖片大小:\", img.size)\n",
        "img"
      ],
      "metadata": {
        "id": "oTQXkodXIfRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建立模型\n",
        "VGG16 不是用 Sequential 堆蛋糕的方式產出  \n",
        "      而是使用 model "
      ],
      "metadata": {
        "id": "bbP3QJ5Id2Sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense, BatchNormalization\n",
        "\n",
        "# CNN \n",
        "# Non-trainable params: 從 0 變為 14,714,688\n",
        "# 固定那些 weight 不再訓練\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False \n",
        "\n",
        "# BN \n",
        "BNed_layers = BatchNormalization()(vgg.output)\n",
        "\n",
        "\n",
        "# MLP\n",
        "temporary_vgg_output = Flatten()(BNed_layers)\n",
        "# VGG16.sumary 最後輸出項有 7 * 7 * 512 = 25088 所以神經元取四位數 2的次方數\n",
        "\n",
        "temporary_layer1 = Dense(units=2048, activation=\"relu\")(temporary_vgg_output)\n",
        "\n",
        "temporary_layer2 = Dense(units=256, activation=\"relu\")(temporary_layer1)\n",
        "\n",
        "temporary_layer3 = Dense(units=64, activation=\"relu\")(temporary_layer2)\n",
        "\n",
        "# 此次分類的資料集 辨識 貓還是狗 \n",
        "# 如辨識結果想要 units = 1 (貓 則其他非貓)   則需要使用 sigmoid\n",
        "# 如辨識結果想要 units = 2 (貓, 狗)。       則需要使用 softmax\n",
        "temporary_layer4 = Dense(units=2 , activation=\"softmax\")(temporary_layer3)\n",
        "\n",
        "cnn = Model(inputs=vgg.input, outputs=temporary_layer4)\n",
        "cnn.summary()\n",
        "# 最後可以看到結果 我們自己在VGG16後面增加了多層神經元"
      ],
      "metadata": {
        "id": "yHxR-oh8dm5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile"
      ],
      "metadata": {
        "id": "EcwAwqVMkbW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(loss=\"categorical_crossentropy\",\n",
        "            optimizer=\"adam\",\n",
        "            metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "KDVFlUgdkdt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 切分 訓練"
      ],
      "metadata": {
        "id": "jzjm_9AkngZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# 真的開始切分和訓練時 必須把pandas 轉換成 numpy array\n",
        "# 捨棄pandas 前面的 index\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "y_catogorical = to_categorical(df[\"target\"])\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(df[\"path\"]),\n",
        "                                                    np.array(y_catogorical),\n",
        "                                                    test_size=0.1)"
      ],
      "metadata": {
        "id": "ZSwg7owJnpjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 問題的資料預處理"
      ],
      "metadata": {
        "id": "Bo6CHK5yY_4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "random_idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "# 下限 0\n",
        "# 上限 22500 (不包括 22500) (平常使用random.randint(0,22500) 會包含22500 但 np.random.randint 不會包含)\n",
        "# batch_size 想要取幾個"
      ],
      "metadata": {
        "id": "Fej29kDepK6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize相類似概念 但當時VGG16的模型訓練者 不是轉化成 0-1 or -1 - 1 \n",
        "# 所以我們也需要依照他的方式 對資料預處理.  (使用誰的模型 進入該模型前的資料預處理 就要用誰的Normalize方式)\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "# 將上方的圖帶入模型 訓練\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "for i in range(20):\n",
        "\n",
        "    random_idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "    # 下限 0\n",
        "    # 上限 22500 (不包括 22500) (平常使用random.randint(0,22500) 會包含22500 但 np.random.randint 不會包含)\n",
        "    # batch_size 想要取幾個\n",
        "\n",
        "    img_list = []\n",
        "\n",
        "    for fn in x_train[random_idx]:\n",
        "        # 讀取圖片 並且使用我們偷來的模型的預處理方式 來預處理資料\n",
        "        img = load_img(fn, target_size=(224, 224))\n",
        "        img = preprocess_input(np.array(img))\n",
        "        img_list.append(img)\n",
        "\n",
        "    x = np.array(img_list)\n",
        "    y = y_train[random_idx]\n",
        "\n",
        "    result = cnn.train_on_batch(x, y)\n",
        "\n",
        "    print(\"-----Times\", i, \"-----\")\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "ihD3Dj3Hrq_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "random_idx = np.random.randint(0, x_test.shape[0], batch_size)\n",
        "\n",
        "ori_img_list = []\n",
        "img_list = []\n",
        "\n",
        "for fn in x_test[random_idx]:\n",
        "    img = load_img(fn, target_size=(224, 224))\n",
        "    # 把原圖留下 等等可以看一下處理前 處理後\n",
        "    ori_img_list.append(img)\n",
        "\n",
        "    img = preprocess_input(np.array(img))\n",
        "    img_list.append(img)\n",
        "\n",
        "x = np.array(img_list)\n",
        "y = y_test[random_idx]\n",
        "\n",
        "cnn.evaluate(x, y)\n",
        "# [16.29060935974121, 0.6650000214576721]\n",
        "# loss距離 , 正確率\n",
        "# 正確率不高 因為少了一個重要步驟 如下"
      ],
      "metadata": {
        "id": "R_Wkve92cRxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = cnn.predict(x).argmax(axis=-1)\n",
        "pre\n",
        "# argmax 比較1 or 0 的機率較大\n",
        "\n",
        "# 發現 幾乎都預測貓 導致正確率低下\n",
        "# relu 死亡問題\n",
        "# 數值離 relu函式 的激活點 太遠 導致神經元跟死亡一樣\n",
        "# 解決方法 : 將 cnn 的輸出值 轉化為 0-1之間 再進入 mlp\n",
        "# 稱為 batch normalization\n",
        "\n",
        "# 調整方法 - batch normalization\n",
        "# 1. 輸入的數據 經過多層神經網絡 數值可能變得非常大或非常小\n",
        "# 2. 非常小的數值 離relu激活點太遠 導致永遠無法激活 (relu 死亡問題)\n",
        "# 3. 激活前 將數值調整到合理的範圍內"
      ],
      "metadata": {
        "id": "0nwzidDfd822"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 作圖\n",
        "pre != y.argmax(axis=-1)\n",
        "# argmax 比較1 or 0 的機率較大\n",
        "\n",
        "np.nonzero(pre != y.argmax(axis=-1))\n",
        "# 找出那些圖示預測錯誤的"
      ],
      "metadata": {
        "id": "rIjFwcp75TuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}